[2022-12-27 14:18:18] mrx-link.MRXLinkMagics.mrxlink_set_parameters() DEBUG: args: Namespace(no_reply=True, base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118213.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118213.0.0.0', cell='[{"name":"a","type":"int","value":"12"}]\n')
[2022-12-27 14:18:18] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118213.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118213.0.0.0', cell='{"nodes":[],"edges":[]}\n')
[2022-12-27 14:18:18] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [], 'edges': []}
[2022-12-27 14:19:18] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118213.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118213.0.0.0', cell='{"nodes":[],"edges":[]}\n')
[2022-12-27 14:19:18] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [], 'edges': []}
[2022-12-27 14:19:20] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118213.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118213.0.0.0', cell='{"nodes":[],"edges":[]}\n')
[2022-12-27 14:19:20] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [], 'edges': []}
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118213.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118213.0.0.0', cell='{"nodes":[],"edges":[]}\n')
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [], 'edges': []}
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118213.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118213.0.0.0', cell='{"nodes":[],"edges":[]}\n')
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [], 'edges': []}
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118560.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118560.0.0.0', cell='{"nodes":[],"edges":[]}\n')
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [], 'edges': []}
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118560.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118560.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}}],"edges":[]}\n')
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}], 'edges': []}
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118591.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118591.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}}],"edges":[]}\n')
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}], 'edges': []}
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118604.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118604.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}}],"edges":[]}\n')
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}], 'edges': []}
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118665.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118665.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}}],"edges":[]}\n')
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}], 'edges': []}
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118692.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118692.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}}],"edges":[]}\n')
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}], 'edges': []}
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118705.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118705.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}}],"edges":[]}\n')
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}], 'edges': []}
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118740.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118740.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}}],"edges":[]}\n')
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}], 'edges': []}
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118754.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118754.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}}],"edges":[]}\n')
[2022-12-27 14:27:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}], 'edges': []}
[2022-12-27 14:28:05] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118881.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118881.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"}]}\n')
[2022-12-27 14:28:05] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}]}
[2022-12-27 14:28:26] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118899.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118899.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"}]}\n')
[2022-12-27 14:28:26] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}]}
[2022-12-27 14:28:37] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118899.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118899.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"}]}\n')
[2022-12-27 14:28:37] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}]}
[2022-12-27 14:28:55] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118927.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118927.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"}]}\n')
[2022-12-27 14:28:55] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}]}
[2022-12-27 14:29:24] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118948.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118948.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":false}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:29:24] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': False}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:29:39] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118979.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672118976.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:29:39] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:29:40] mrx-link.MRXLinkMagics.mrxlink_execute_node() DEBUG: args: Namespace(id='b0ac5426-1782-4b96-9499-06704770a75f', type='CodeCell', name='Unknown', cell='max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)\n')
[2022-12-27 14:31:13] mrx-link.MRXLinkMagics.mrxlink_set_parameters() DEBUG: args: Namespace(no_reply=False, base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119066.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119066.0.0.0', cell='[{"name":"a","value":"1"}]\n')
[2022-12-27 14:31:21] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119066.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119066.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:31:21] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:31:29] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119066.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119066.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:31:29] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:31:52] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119066.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119066.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:31:52] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:31:58] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119066.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119066.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:31:58] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:32:06] mrx-link.MRXLinkMagics.mrxlink_set_parameters() DEBUG: args: Namespace(no_reply=False, base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119066.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119066.0.0.0', cell='[{"name":"a","value":"1"},{"name":"learning_rate","value":"0.001"},{"name":"max_epoch","value":"10"}]\n')
[2022-12-27 14:32:13] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119133.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119066.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:32:13] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:32:16] mrx-link.MRXLinkMagics.mrxlink_execute_node() DEBUG: args: Namespace(id='b0ac5426-1782-4b96-9499-06704770a75f', type='CodeCell', name='Unknown', cell='#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)\n')
[2022-12-27 14:35:48] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119337.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119139.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:35:48] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:35:53] mrx-link.MRXLinkMagics.mrxlink_set_parameters() DEBUG: args: Namespace(no_reply=True, base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119347.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119347.0.0.0', cell='[{"name":"a","value":"1","type":"int"},{"name":"learning_rate","value":"0.001","type":"float"},{"name":"max_epoch","value":"10","type":"int"}]\n')
[2022-12-27 14:36:03] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119347.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119347.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:36:03] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:37:14] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119347.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119347.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:37:14] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:37:37] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119347.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119347.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:37:37] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:38:31] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119509.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119509.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:38:31] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:38:46] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119509.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119509.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:38:46] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:39:15] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119540.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119540.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[{"writer":"hyeonji","message":"comenttt"}],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:39:15] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [{'writer': 'hyeonji', 'message': 'comenttt'}], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:41:09] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119622.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119622.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[{"writer":"hyeonji","message":"comenttt"}],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)\\n","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:41:09] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [{'writer': 'hyeonji', 'message': 'comenttt'}], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)\n', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:41:20] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119622.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119622.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[{"writer":"hyeonji","message":"comenttt"}],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)\\n\\n","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:41:20] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [{'writer': 'hyeonji', 'message': 'comenttt'}], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)\n\n', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:42:59] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119622.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119622.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[{"writer":"hyeonji","message":"comenttt"}],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)\\n\\nl","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:42:59] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [{'writer': 'hyeonji', 'message': 'comenttt'}], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)\n\nl', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:43:10] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119622.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672119622.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[{"writer":"hyeonji","message":"comenttt"}],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)\\n\\nlogger.","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:43:10] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [{'writer': 'hyeonji', 'message': 'comenttt'}], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)\n\nlogger.', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
[2022-12-27 14:54:33] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://192.168.1.18:8888/', header='Accept-Encoding=gzip,%20deflate,%20br;Host=192.168.1.18:8888', cookie='_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20_ga=GA1.1.2100713857.1672036856;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672120394.0.0.0;%20_xsrf=2%7C13751b7e%7C237a8e62d8444110a1a3ba0b2c57f64d%7C1672036839;%20username-192-168-1-18-8889=2%7C1:0%7C10:1672036846%7C26:username-192-168-1-18-8889%7C44:ZmI3MWMzNjI3M2UwNDJkN2ExMzU1NjhjZGNlYzU5ZDU=%7C6b64a4b1049f714359afe553ffb3c69cc00abb85c8a4cf77caecf957be198b2d;%20_ga=GA1.1.2100713857.1672036856;%20username-192-168-1-18-8888=2%7C1:0%7C10:1672116700%7C26:username-192-168-1-18-8888%7C44:MTIwMDA4NWJlZDNkNGVhNDk3NWJlZGI1MDk5ODYxZGU=%7C98b67f97077d5d06ab65db24a769612c1fc1bd3497e69897a8348f377630f4d5;%20_ga_R3VN4GNEX2=GS1.1.1672116705.2.1.1672120394.0.0.0', cell='{"nodes":[{"id":"ea60a934-8658-4129-9cef-e1bbc32f48d2","name":"Load Iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[{"writer":"hyeonji","message":"comenttt"}],"diskcache":true}},{"id":"7f47bc5c-de01-41ba-aec2-08c194b882ed","name":"Create data frame","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","name":"train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"da9f8eb3-7d26-4044-9d30-c6cb21530085","name":"create dataloader","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"#FF004F","comments":[],"diskcache":true}},{"id":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","name":"def pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(task=\\"multiclass\\", num_classes=3),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"2bc7816b-c947-4d6f-892f-e0db93d5b982","name":"create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"#0093FF","comments":[],"diskcache":true}},{"id":"268cfa1a-531c-4404-976a-6e97384ac5b0","name":"def liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch and \\"valid_loss\\" in metrics:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}},{"id":"b0ac5426-1782-4b96-9499-06704770a75f","name":"train model","code":"#max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\\ntrainer.fit(model, train_loader, valid_loader)\\n\\nlogger.","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[],"diskcache":true}}],"edges":[{"parent":"ea60a934-8658-4129-9cef-e1bbc32f48d2","child":"7f47bc5c-de01-41ba-aec2-08c194b882ed"},{"parent":"7f47bc5c-de01-41ba-aec2-08c194b882ed","child":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848"},{"parent":"35bb8cc2-eee3-4857-8f2d-ce2e810ee848","child":"da9f8eb3-7d26-4044-9d30-c6cb21530085"},{"parent":"964f0b9a-dab5-48a3-88d3-5bdffcc53d49","child":"2bc7816b-c947-4d6f-892f-e0db93d5b982"},{"parent":"268cfa1a-531c-4404-976a-6e97384ac5b0","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"2bc7816b-c947-4d6f-892f-e0db93d5b982","child":"b0ac5426-1782-4b96-9499-06704770a75f"},{"parent":"da9f8eb3-7d26-4044-9d30-c6cb21530085","child":"b0ac5426-1782-4b96-9499-06704770a75f"}]}\n')
[2022-12-27 14:54:33] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'name': 'Load Iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [{'writer': 'hyeonji', 'message': 'comenttt'}], 'diskcache': True}}, {'id': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'name': 'Create data frame', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'name': 'train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'name': 'create dataloader', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#FF004F', 'comments': [], 'diskcache': True}}, {'id': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'name': 'def pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(task="multiclass", num_classes=3),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'name': 'create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': '#0093FF', 'comments': [], 'diskcache': True}}, {'id': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'name': 'def liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch and "valid_loss" in metrics:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}, {'id': 'b0ac5426-1782-4b96-9499-06704770a75f', 'name': 'train model', 'code': '#max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], enable_progress_bar=False)\ntrainer.fit(model, train_loader, valid_loader)\n\nlogger.', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': [], 'diskcache': True}}], 'edges': [{'parent': 'ea60a934-8658-4129-9cef-e1bbc32f48d2', 'child': '7f47bc5c-de01-41ba-aec2-08c194b882ed'}, {'parent': '7f47bc5c-de01-41ba-aec2-08c194b882ed', 'child': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848'}, {'parent': '35bb8cc2-eee3-4857-8f2d-ce2e810ee848', 'child': 'da9f8eb3-7d26-4044-9d30-c6cb21530085'}, {'parent': '964f0b9a-dab5-48a3-88d3-5bdffcc53d49', 'child': '2bc7816b-c947-4d6f-892f-e0db93d5b982'}, {'parent': '268cfa1a-531c-4404-976a-6e97384ac5b0', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': '2bc7816b-c947-4d6f-892f-e0db93d5b982', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}, {'parent': 'da9f8eb3-7d26-4044-9d30-c6cb21530085', 'child': 'b0ac5426-1782-4b96-9499-06704770a75f'}]}
